{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from scipy import stats\n",
    "import time\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "dataset = pd.read_csv('Final_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (95568, 22)\n",
      "-----------------------\n",
      "Dropping zeros from HC\n",
      "Dropped 1124 rows\n",
      "Dataset shape: (94444, 22)\n",
      "-----------------------\n",
      "Dropping zeros from CO\n",
      "Dropped 2791 rows\n",
      "Dataset shape: (91653, 22)\n",
      "-----------------------\n",
      "Dropping zeros from CO2\n",
      "Dropped 11 rows\n",
      "Dataset shape: (91642, 22)\n",
      "-----------------------\n",
      "Dropping zeros from NOX\n",
      "Dropped 13503 rows\n",
      "Dataset shape: (78139, 22)\n"
     ]
    }
   ],
   "source": [
    "# Drop MPG and PM columns\n",
    "dataset = dataset.drop(columns=['PM', 'MPG'])\n",
    "print('Dataset shape: {}'.format(dataset.shape))\n",
    "print('-----------------------')\n",
    "rows = dataset.shape[0]\n",
    "\n",
    "# Drop all rows that have zeros\n",
    "dataset = dataset[dataset.HC != 0]\n",
    "print('Dropping zeros from HC')\n",
    "print('Dropped {} rows'.format(rows - dataset.shape[0]))\n",
    "print('Dataset shape: {}'.format(dataset.shape))\n",
    "print('-----------------------')\n",
    "rows = dataset.shape[0]\n",
    "\n",
    "dataset = dataset[dataset.CO != 0]\n",
    "print('Dropping zeros from CO')\n",
    "print('Dropped {} rows'.format(rows - dataset.shape[0]))\n",
    "print('Dataset shape: {}'.format(dataset.shape))\n",
    "print('-----------------------')\n",
    "rows = dataset.shape[0]\n",
    "\n",
    "dataset = dataset[dataset.CO2 != 0]\n",
    "print('Dropping zeros from CO2')\n",
    "print('Dropped {} rows'.format(rows - dataset.shape[0]))\n",
    "print('Dataset shape: {}'.format(dataset.shape))\n",
    "print('-----------------------')\n",
    "rows = dataset.shape[0]\n",
    "\n",
    "dataset = dataset[dataset.Nox != 0]\n",
    "print('Dropping zeros from NOX')\n",
    "print('Dropped {} rows'.format(rows - dataset.shape[0]))\n",
    "print('Dataset shape: {}'.format(dataset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success with feature: Year\n",
      "Success with feature: Vehicle_Code\n",
      "Success with feature: Manufacturer_Code\n",
      "Success with feature: Displacement\n",
      "Success with feature: Fuel_System\n",
      "Success with feature: Gears\n",
      "Success with feature: Transmission_Code\n",
      "Success with feature: ETW\n",
      "Success with feature: HP\n",
      "Success with feature: Drive_System_Code\n",
      "Success with feature: Fuel_Code\n",
      "Success with feature: V_avg\n",
      "Success with feature: V_max\n",
      "Success with feature: V_std\n",
      "Success with feature: a_pos\n",
      "Success with feature: a_neg\n",
      "Success with feature: Peak_pos\n",
      "Success with feature: Peak_neg\n",
      "Success with feature: HC\n",
      "Success with feature: CO\n",
      "Success with feature: CO2\n",
      "Success with feature: Nox\n"
     ]
    }
   ],
   "source": [
    "# Scale date from 0 to 1\n",
    "\n",
    "# Create an empty list to put all the scalers\n",
    "scalers = []\n",
    "\n",
    "# Create different scalers for each feature in the dataset\n",
    "for i in range(np.size(dataset.columns)):\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    scalers.append(scaler)\n",
    "\n",
    "# Create a copy to avoid damaging the original data\n",
    "data_scaled = dataset.copy()\n",
    "\n",
    "# Fill NAN values with 0\n",
    "data_scaled = data_scaled.fillna(value=0)\n",
    "\n",
    "# Scale all the features from 0 to 1\n",
    "for i in range(np.size(dataset.columns)):\n",
    "    \n",
    "    col_name = dataset.columns[i]\n",
    "    \n",
    "    values = data_scaled[col_name].values\n",
    "    values = values.astype('float64')\n",
    "    values = values.reshape(values.shape[0],1)\n",
    "    \n",
    "    data_scaled[col_name] = scalers[i].fit_transform(values)\n",
    "    \n",
    "    print('Success with feature: {}'.format(col_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export scalers for later use\n",
    "for i in range(np.size(dataset.columns)):\n",
    "    \n",
    "    scaler_filename = \"Scalers/scaler{}.save\".format(i)\n",
    "    scaler = scalers[i]\n",
    "    joblib.dump(scaler, scaler_filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
