{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "\n",
    "### This Notebook:\n",
    "\n",
    "This notebook will run a test to see if a model can accurately predict emissions for vehicles **AFTER YEAR 2009**. \n",
    "\n",
    "* Activation Functions:\n",
    "    * Leaky ReLU + Linear Output\n",
    "* Optimizers:\n",
    "    * Adam\n",
    "* Dropout:\n",
    "    * 20%\n",
    "* Loss Function:\n",
    "    * MAPE (Mean Absolute Percentage Error)\n",
    "* Scaler:\n",
    "    * MinMax\n",
    "    \n",
    "There will be an analysis of the manufacturers in the data-base and with this, different data-sets to train the models will be created. \n",
    "\n",
    "    1) Create a data-set with 18 inputs for the manufacturer with the most cars\n",
    "    2) Create 18 independent databases by dropping one input at a time\n",
    "    3) Apply PCA for 99% and 90% to the first database\n",
    "    \n",
    "This totals 21 models to be trained and tested\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "## TO DO's\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drllc\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Input, Dense, Dropout, advanced_activations, BatchNormalization, LeakyReLU\n",
    "from keras import losses, optimizers, activations\n",
    "import keras.backend as K\n",
    "\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join('.','output')\n",
    "minmax_scaler_path = os.path.join('.','Scalers','MinMax')\n",
    "standard_scaler_path = os.path.join('.','Scalers','Standard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Original Scaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled dataset loaded.\n"
     ]
    }
   ],
   "source": [
    "complete_data_scaled_shuffled = pd.read_csv('Dataset_Scaled_Shuffled.csv')\n",
    "print('Shuffled dataset loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MinMax Scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to put all the scalers\n",
    "minmax_scalers = []\n",
    "\n",
    "for i in range(len(complete_data_scaled_shuffled.columns)):\n",
    "    \n",
    "    scaler_filename = os.path.join(minmax_scaler_path,'scaler{}.save'.format(i))\n",
    "    minmax_scaler = joblib.load(scaler_filename)\n",
    "    \n",
    "    minmax_scalers.append(minmax_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse Scale Data\n",
    "\n",
    "Using the original MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success with feature: Year\n",
      "Success with feature: Vehicle_Code\n",
      "Success with feature: Manufacturer_Code\n",
      "Success with feature: Displacement\n",
      "Success with feature: Fuel_System\n",
      "Success with feature: Gears\n",
      "Success with feature: Transmission_Code\n",
      "Success with feature: ETW\n",
      "Success with feature: HP\n",
      "Success with feature: Drive_System_Code\n",
      "Success with feature: Fuel_Code\n",
      "Success with feature: V_avg\n",
      "Success with feature: V_max\n",
      "Success with feature: V_std\n",
      "Success with feature: a_pos\n",
      "Success with feature: a_neg\n",
      "Success with feature: Peak_pos\n",
      "Success with feature: Peak_neg\n",
      "Success with feature: HC\n",
      "Success with feature: CO\n",
      "Success with feature: CO2\n",
      "Success with feature: Nox\n"
     ]
    }
   ],
   "source": [
    "# First, inverse transform all original values from the test_set\n",
    "original_data_inverse = complete_data_scaled_shuffled.copy()\n",
    "\n",
    "for i in range(len(complete_data_scaled_shuffled.columns)):\n",
    "    \n",
    "    col_name = complete_data_scaled_shuffled.columns[i]\n",
    "    \n",
    "    values = original_data_inverse[col_name].values\n",
    "    values = values.astype('float64')\n",
    "    values = values.reshape(values.shape[0],1)\n",
    "    \n",
    "    original_data_inverse[col_name] = minmax_scalers[i].inverse_transform(values)\n",
    "    \n",
    "    print('Success with feature: {}'.format(col_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop info prior to year 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "data_after_2009 = original_data_inverse[original_data_inverse.Year >= 2010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale Data\n",
    "\n",
    "Function to scale data according to an input that decides if it is a MinMax or a Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(data, scaler_type):\n",
    "    \n",
    "    # Select the scalers\n",
    "    if scaler_type == 'MinMax':\n",
    "        \n",
    "        scalers = minmax_scalers\n",
    "        print('Using {} Scalers'.format(scaler_type))\n",
    "        print('----------------------------------')\n",
    "        \n",
    "    if scaler_type == 'Standard':\n",
    "        \n",
    "        scalers = standard_scalers\n",
    "        print('Using {} Scalers'.format(scaler_type))\n",
    "        print('----------------------------------')\n",
    "        \n",
    "    # Scale the data\n",
    "    \n",
    "    # Copy the data set to avoid altering the original\n",
    "    new_data_scaled = data.copy()\n",
    "    \n",
    "    # DROP THE VARIABLES WE DON'T WANT\n",
    "    #new_data_scaled.drop(columns=['Fuel_Code', 'Drive_System_Code', 'Peak_pos', 'Peak_neg', 'ETW', 'a_pos', 'a_neg', 'HP'], \n",
    "                     #inplace=True)\n",
    "    \n",
    "    # Loop over the standard_scalers and perform the scaling operation on each column\n",
    "    for i in range(len(new_data_scaled.columns)):\n",
    "\n",
    "        col_name = new_data_scaled.columns[i]\n",
    "\n",
    "        values = new_data_scaled[col_name].values\n",
    "        values = values.astype('float64')\n",
    "        values = values.reshape(values.shape[0],1)\n",
    "\n",
    "        new_data_scaled[col_name] = scalers[i].fit_transform(values)\n",
    "\n",
    "        print('Success with feature: {}'.format(col_name))\n",
    "    \n",
    "    print('----------------------------------')\n",
    "    \n",
    "    return new_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_types = ['MinMax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MinMax Scalers\n",
      "----------------------------------\n",
      "Success with feature: Year\n",
      "Success with feature: Vehicle_Code\n",
      "Success with feature: Manufacturer_Code\n",
      "Success with feature: Displacement\n",
      "Success with feature: Fuel_System\n",
      "Success with feature: Gears\n",
      "Success with feature: Transmission_Code\n",
      "Success with feature: ETW\n",
      "Success with feature: HP\n",
      "Success with feature: Drive_System_Code\n",
      "Success with feature: Fuel_Code\n",
      "Success with feature: V_avg\n",
      "Success with feature: V_max\n",
      "Success with feature: V_std\n",
      "Success with feature: a_pos\n",
      "Success with feature: a_neg\n",
      "Success with feature: Peak_pos\n",
      "Success with feature: Peak_neg\n",
      "Success with feature: HC\n",
      "Success with feature: CO\n",
      "Success with feature: CO2\n",
      "Success with feature: Nox\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "data_minmax_scaled = scale_data(data_after_2009, 'MinMax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "Function to prepare data based on the database input, which depends on the souce (Top or 500) and the scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size = 19263\n",
      "Dev Size = 2408\n",
      "Test Size = 2408\n",
      "Remainder = 0\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Get number of data points\n",
    "data_points = data_after_2009.shape[0]\n",
    "\n",
    "# Set sizes for train, dev, test sets\n",
    "train_percent = 0.8\n",
    "train_size = round(train_percent*data_points)\n",
    "\n",
    "if (data_points-train_size)%2 == 0:\n",
    "    dev_size = int((data_points-train_size)/2)\n",
    "    test_size = dev_size\n",
    "    print('Train Size = {}'.format(train_size))\n",
    "    print('Dev Size = {}'.format(dev_size))\n",
    "    print('Test Size = {}'.format(test_size))\n",
    "    print('Remainder = {}'.format(train_size+dev_size+test_size-data_points))\n",
    "    print('----------------------------------')\n",
    "\n",
    "else:\n",
    "    train_size = train_size-1\n",
    "    dev_size = int((data_points-train_size)/2)\n",
    "    test_size = dev_size \n",
    "    print('Train Size = {}'.format(train_size))\n",
    "    print('Dev Size = {}'.format(dev_size))\n",
    "    print('Test Size = {}'.format(test_size))\n",
    "    print('Remainder = {}'.format(train_size+dev_size+test_size-data_points))\n",
    "    print('----------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Datasets\n",
    "\n",
    "Create functions to modify the input variables and thus create different input sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the names of the columns in a list that can be looped\n",
    "input_names = complete_data_scaled_shuffled.columns[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year\n",
      "Vehicle_Code\n",
      "Manufacturer_Code\n",
      "Displacement\n",
      "Fuel_System\n",
      "Gears\n",
      "Transmission_Code\n",
      "ETW\n",
      "HP\n",
      "Drive_System_Code\n",
      "Fuel_Code\n",
      "V_avg\n",
      "V_max\n",
      "V_std\n",
      "a_pos\n",
      "a_neg\n",
      "Peak_pos\n",
      "Peak_neg\n"
     ]
    }
   ],
   "source": [
    "for variable in input_names:\n",
    "    print('{}'.format(variable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_sets(data, drop_variable=None):\n",
    "    \n",
    "    # Create a local copy of the entire dataset\n",
    "    data_scaled_shuffled = data.copy()\n",
    "    \n",
    "    if drop_variable != None:\n",
    "        # Drop the variable that will be ignored during the run\n",
    "        data_scaled_shuffled.drop(columns=drop_variable, inplace=True)\n",
    "        print('{} Column Dropped'.format(drop_variable))\n",
    "    \n",
    "    print('Preparing Data-sets')\n",
    "    # Divide data into train, dev, and test sets\n",
    "    train_set = data_scaled_shuffled[ : train_size]\n",
    "    dev_set = data_scaled_shuffled[train_size : train_size+dev_size]\n",
    "    test_set = data_scaled_shuffled[train_size+dev_size : train_size+dev_size+test_size]\n",
    "\n",
    "    # Reset index for all sets\n",
    "    train_set = train_set.reset_index(drop=True)\n",
    "    dev_set = dev_set.reset_index(drop=True)\n",
    "    test_set = test_set.reset_index(drop=True)\n",
    "\n",
    "    # Get values\n",
    "    train_set_values = train_set.values\n",
    "    dev_set_values = dev_set.values\n",
    "    test_set_values = test_set.values\n",
    "    \n",
    "    # Number of emissions: HC, CO, CO2, NOX\n",
    "    n_out = 4\n",
    "    \n",
    "    print('Splitting into inputs and outputs')\n",
    "    # SLICING: [start row:end row , start column:end column]\n",
    "    # Split into inputs and outputs\n",
    "    x_train = train_set_values[:,:-n_out]\n",
    "    x_dev = dev_set_values[:,:-n_out]\n",
    "    x_test = test_set_values[:,:-n_out]\n",
    "    \n",
    "    print('Inputs = {}'.format(x_train.shape[1]))\n",
    "    \n",
    "    # Get the outputs (only HC)\n",
    "    HC_train = train_set_values[:,-n_out]\n",
    "    HC_dev = dev_set_values[:,-n_out]\n",
    "    HC_test = test_set_values[:,-n_out]\n",
    "    \n",
    "    print('Data-sets complete')\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    return x_train, x_dev, x_test, HC_train, HC_dev, HC_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_inverse(scaler_type):\n",
    "    \n",
    "    # Select the scalers\n",
    "    if scaler_type == 'MinMax':\n",
    "        \n",
    "        scalers = minmax_scalers\n",
    "        \n",
    "    if scaler_type == 'Standard':\n",
    "        \n",
    "        scalers = standard_scalers\n",
    "        \n",
    "    #----------------------------------\n",
    "\n",
    "    # Inverse transform the TEST DATA to be able to calculate the error further down\n",
    "    test_set_scaled = data_after_2009[train_size+dev_size : train_size+dev_size+test_size]\n",
    "    test_set_inverse = test_set_scaled.copy()\n",
    "\n",
    "    for i in range(np.size(data_after_2009.columns)):\n",
    "\n",
    "        col_name = data_after_2009.columns[i]\n",
    "\n",
    "        values = test_set_inverse[col_name].values\n",
    "        values = values.astype('float64')\n",
    "        values = values.reshape(values.shape[0],1)\n",
    "\n",
    "        test_set_inverse[col_name] = scalers[i].inverse_transform(values)\n",
    "\n",
    "    print('Success creating inverse test set')\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    return test_set_inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "\n",
    "Create a function that creates a PCA instance and with that PCA instance creates a new x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pca_set(variance_amount, x_train, x_dev, x_test):\n",
    "    \n",
    "    if variance_amount < 1:\n",
    "    \n",
    "        print('Create PCA Instance')\n",
    "        pca = PCA(variance_amount)\n",
    "\n",
    "        print('Fit PCA Instance')\n",
    "        pca.fit(x_train)\n",
    "        print('Number of Components = {}'.format(pca.n_components_))\n",
    "\n",
    "        print('Create New Input Training Set')\n",
    "        new_x_train = pca.transform(x_train)\n",
    "\n",
    "        print('Create New Input Dev Set')\n",
    "        new_x_dev = pca.transform(x_dev)\n",
    "\n",
    "        print('Create New Input Test Set')\n",
    "        new_x_test = pca.transform(x_test)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        new_x_train = x_train\n",
    "        new_x_dev = x_dev\n",
    "        new_x_test = x_test\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    return new_x_train, new_x_dev, new_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_options = [1, 0.99, 0.90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini-batch size, epochs\n",
    "batch_size = 64\n",
    "epochs = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-Parameter Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation functions to try\n",
    "names_activations = ['LReLU']\n",
    "    # A function has to be called so that a new instance of the function can be created in each layer\n",
    "def get_activation(name):\n",
    "    \n",
    "    if name == 'ReLU':\n",
    "        function = advanced_activations.ReLU()\n",
    "    if name == 'LReLU':\n",
    "        function = advanced_activations.LeakyReLU()\n",
    "        \n",
    "    return function\n",
    "\n",
    "#--------------------------------------------------------------------------------- \n",
    "\n",
    "output_activations = ['linear']\n",
    "\n",
    "#--------------------------------------------------------------------------------- \n",
    "\n",
    "# Dropout rate to be tried\n",
    "dropouts = [0.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(number, x_train, activation_name, output, dd):\n",
    "    \n",
    "    # Create model\n",
    "    model = Sequential(name='Model_{}'.format(number))\n",
    "\n",
    "    model.add(Dense(256, input_dim=x_train.shape[1]))\n",
    "    model.add(get_activation(activation_name))\n",
    "    model.add(Dropout(dd))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(get_activation(activation_name))\n",
    "    model.add(Dropout(dd))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    model.add(get_activation(activation_name))\n",
    "    model.add(Dropout(dd))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(32))\n",
    "    model.add(get_activation(activation_name))\n",
    "    model.add(Dropout(dd))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(16))\n",
    "    model.add(get_activation(activation_name))\n",
    "    model.add(Dropout(dd))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    if output == 'ReLU':\n",
    "        model.add(advanced_activations.ReLU())\n",
    "\n",
    "    #Compile model\n",
    "    model.compile(loss=losses.mean_absolute_percentage_error, optimizer=optimizers.Adam(), metrics = ['accuracy'])\n",
    "    \n",
    "    print('{} Created'.format(model.name))\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(model, x_train, y_train, x_dev, y_dev):\n",
    "    \n",
    "    print('{} - Training'.format(model.name))\n",
    "    print('- Started on {} at {}'.format(str(datetime.datetime.now())[5:-16], str(datetime.datetime.now())[11:-10]))\n",
    "    # Start timer\n",
    "    start_time = time.time()\n",
    "\n",
    "    # fit network\n",
    "    history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, \n",
    "                        validation_data=(x_dev, y_dev), verbose=0, shuffle=True)\n",
    "\n",
    "    # End timer\n",
    "    end_time = time.time() - start_time\n",
    "    print('{} - Training Complete'.format(model.name))\n",
    "    print('- Time: {:.3f} min'.format(end_time/60))\n",
    "    print('- Loss = {:.5f}'.format(history.history['loss'][-1]))\n",
    "    print('- Val Loss = {:.5f}'.format(history.history['val_loss'][-1]))\n",
    "    print('----------------------------------')\n",
    "        \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Predictions and Calculate Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to define MSPE\n",
    "def msp_error(true,pred):\n",
    "    error = 100*np.sum(((true-pred)/true)**2)/np.size(true)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_get_error(model, x_test, scaler_type, test_set_inverse):\n",
    "    \n",
    "        # Select the scalers\n",
    "    if scaler_type == 'MinMax':\n",
    "        \n",
    "        scalers = minmax_scalers\n",
    "        \n",
    "    if scaler_type == 'Standard':\n",
    "        \n",
    "        scalers = standard_scalers  \n",
    "    \n",
    "    #------------------\n",
    "    print('Predicting with {}'.format(model.name))\n",
    "    scaled_predictions = model.predict(x_test)\n",
    "    \n",
    "    print('Inverse Scaling Operation') \n",
    "     \n",
    "    # Inverse the scaling operation on the predictions\n",
    "    predictions = scalers[-4].inverse_transform(scaled_predictions)\n",
    "    \n",
    "    print('- Prediction Mean = {:.5f}'.format(np.mean(predictions)))\n",
    "    print('- Prediction Min = {:.5f}'.format(np.min(predictions)))\n",
    "    print('- Prediction Max = {:.5f}'.format(np.max(predictions)))\n",
    "\n",
    "    print('Calculating HC Error')\n",
    "    mspe = msp_error(test_set_inverse['HC'].values, predictions)\n",
    "        \n",
    "    print('- HC Error  = {:.2e}'.format(mspe))\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    return mspe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Models and Rank with MSPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_models():\n",
    "    \n",
    "    count = 1\n",
    "    model_list = []\n",
    "    history_list = []\n",
    "    HC_error_list = []\n",
    "        \n",
    "    for scaler_type in scaler_types:\n",
    "\n",
    "        for activation_name in names_activations:\n",
    "\n",
    "            for output in output_activations:\n",
    "\n",
    "                for dd in dropouts:\n",
    "                    \n",
    "                    for variable in input_names:\n",
    "\n",
    "                        # Print model variables\n",
    "                        print('Model_{} Variables:'.format(count))\n",
    "                        print('- Loss: MAPE')\n",
    "                        print('- Activation: {}'.format(activation_name))\n",
    "                        print('- Output: {}'.format(output))\n",
    "                        print('- Optimizer: Adam')\n",
    "                        print('- Dropout: {}%'.format(dd*100))\n",
    "                        print('- Scaler: {}'.format(scaler_type))\n",
    "                        print('- Dropped: {}'.format(variable))\n",
    "                        print('----------------------------------')\n",
    "                        \n",
    "                        data_scaled = data_minmax_scaled.copy()\n",
    "\n",
    "                        # Prepare data-sets and create inputs and outputs\n",
    "                        x_train, x_dev, x_test, y_train, y_dev, y_test = prepare_data_sets(data_scaled, variable)\n",
    "\n",
    "                        # Create model\n",
    "                        model = build_model(count, x_train, activation_name, output, dd)\n",
    "\n",
    "                        # Train model\n",
    "                        history = train_models(model, x_train, y_train, x_dev, y_dev)\n",
    "                        history_list.append(history)\n",
    "\n",
    "                        # Get test_set_inverse\n",
    "                        test_set_inverse = get_test_inverse(scaler_type)\n",
    "\n",
    "                        # Make predictions and calculate error\n",
    "                        error = predict_get_error(model, x_test, scaler_type, test_set_inverse)\n",
    "\n",
    "                        # Add error to error list\n",
    "                        HC_error_list.append([model.name, scaler_type, activation_name, output, dd, variable, error])\n",
    "\n",
    "                        # Announce one model process ended\n",
    "                        print('============== MODEL {} PROCESS END =============='.format(count))\n",
    "                        print(' ')\n",
    "\n",
    "                        # Increase counter by 1\n",
    "                        count = count+1\n",
    "\n",
    "                        # Add TRAINED model to list\n",
    "                        model_list.append(model)\n",
    "                        \n",
    "                        \n",
    "    # Create THREE PCA database\n",
    "    for variance_amount in pca_options:\n",
    "        \n",
    "        scaler_type = 'MinMax'\n",
    "        activation_name = 'LReLU'\n",
    "        output = 'linear'\n",
    "        dd = 0.2\n",
    "        \n",
    "        # Print model variables\n",
    "        print('Model_{} Variables:'.format(count))\n",
    "        print('- Loss: MAPE')\n",
    "        print('- Activation: {}'.format(activation_name))\n",
    "        print('- Output: {}'.format(output))\n",
    "        print('- Optimizer: Adam')\n",
    "        print('- Dropout: {}%'.format(dd*100))\n",
    "        print('- Scaler: {}'.format(scaler_type))\n",
    "        print('- Variance: {}'.format(variance_amount))\n",
    "        print('----------------------------------')\n",
    "        \n",
    "        # Prepare data-sets and create inputs and outputs\n",
    "        old_x_train, old_x_dev, old_x_test, y_train, y_dev, y_test = prepare_data_sets(data_minmax_scaled)\n",
    "        \n",
    "        # Create PCA instance for the inputs\n",
    "        x_train, x_dev, x_test = create_pca_set(variance_amount, old_x_train, old_x_dev, old_x_test)\n",
    "\n",
    "        # Create model\n",
    "        model = build_model(count, x_train, activation_name, output, dd)\n",
    "\n",
    "        # Train model\n",
    "        history = train_models(model, x_train, y_train, x_dev, y_dev)\n",
    "        history_list.append(history)\n",
    "\n",
    "        # Get test_set_inverse\n",
    "        test_set_inverse = get_test_inverse(scaler_type)\n",
    "\n",
    "        # Make predictions and calculate error\n",
    "        error = predict_get_error(model, x_test, scaler_type, test_set_inverse)\n",
    "\n",
    "        # Add error to error list\n",
    "        HC_error_list.append([model.name, scaler_type, activation_name, output, dd, variance_amount, error])\n",
    "\n",
    "        # Announce one model process ended\n",
    "        print('============== MODEL {} PROCESS END =============='.format(count))\n",
    "        print(' ')\n",
    "\n",
    "        # Increase counter by 1\n",
    "        count = count+1\n",
    "\n",
    "        # Add TRAINED model to list\n",
    "        model_list.append(model)\n",
    "    \n",
    "    #------------------------------------------------------------\n",
    "\n",
    "    print('Creating DataFrame')                \n",
    "    HC_error = pd.DataFrame(HC_error_list)\n",
    "\n",
    "    print('Changing DataFrame column names')\n",
    "    HC_error.columns = ['Model', 'Scaler', 'Activation', 'Output', 'Dropout', 'Variable/Variance', 'MSPE']\n",
    "\n",
    "    print('Ranking Models')\n",
    "    HC_error.sort_values(by=['MSPE'], inplace=True)\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    return HC_error, model_list, history_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1 Variables:\n",
      "- Loss: MAPE\n",
      "- Activation: LReLU\n",
      "- Output: linear\n",
      "- Optimizer: Adam\n",
      "- Dropout: 20.0%\n",
      "- Scaler: MinMax\n",
      "- Dropped: Year\n",
      "----------------------------------\n",
      "Year Column Dropped\n",
      "Preparing Data-sets\n",
      "Splitting into inputs and outputs\n",
      "Inputs = 17\n",
      "Data-sets complete\n",
      "----------------------------------\n",
      "Model_1 Created\n",
      "----------------------------------\n",
      "Model_1 - Training\n",
      "- Started on 05-08 at 12:23\n",
      "Model_1 - Training Complete\n",
      "- Time: 12.850 min\n",
      "- Loss = 1081.39572\n",
      "- Val Loss = 183.18381\n",
      "----------------------------------\n",
      "Success creating inverse test set\n",
      "----------------------------------\n",
      "Predicting with Model_1\n",
      "Inverse Scaling Operation\n",
      "- Prediction Mean = 0.00280\n",
      "- Prediction Min = 0.00253\n",
      "- Prediction Max = 0.01095\n",
      "Calculating HC Error\n",
      "- HC Error  = 1.03e+08\n",
      "----------------------------------\n",
      "============== MODEL 1 PROCESS END ==============\n",
      " \n",
      "Model_2 Variables:\n",
      "- Loss: MAPE\n",
      "- Activation: LReLU\n",
      "- Output: linear\n",
      "- Optimizer: Adam\n",
      "- Dropout: 20.0%\n",
      "- Scaler: MinMax\n",
      "- Dropped: Vehicle_Code\n",
      "----------------------------------\n",
      "Vehicle_Code Column Dropped\n",
      "Preparing Data-sets\n",
      "Splitting into inputs and outputs\n",
      "Inputs = 17\n",
      "Data-sets complete\n",
      "----------------------------------\n",
      "Model_2 Created\n",
      "----------------------------------\n",
      "Model_2 - Training\n",
      "- Started on 05-08 at 12:36\n",
      "Model_2 - Training Complete\n",
      "- Time: 13.133 min\n",
      "- Loss = 1025.56560\n",
      "- Val Loss = 165.08005\n",
      "----------------------------------\n",
      "Success creating inverse test set\n",
      "----------------------------------\n",
      "Predicting with Model_2\n",
      "Inverse Scaling Operation\n",
      "- Prediction Mean = 0.00224\n",
      "- Prediction Min = -0.00033\n",
      "- Prediction Max = 0.00238\n",
      "Calculating HC Error\n",
      "- HC Error  = 6.25e+07\n",
      "----------------------------------\n",
      "============== MODEL 2 PROCESS END ==============\n",
      " \n",
      "Model_3 Variables:\n",
      "- Loss: MAPE\n",
      "- Activation: LReLU\n",
      "- Output: linear\n",
      "- Optimizer: Adam\n",
      "- Dropout: 20.0%\n",
      "- Scaler: MinMax\n",
      "- Dropped: Manufacturer_Code\n",
      "----------------------------------\n",
      "Manufacturer_Code Column Dropped\n",
      "Preparing Data-sets\n",
      "Splitting into inputs and outputs\n",
      "Inputs = 17\n",
      "Data-sets complete\n",
      "----------------------------------\n",
      "Model_3 Created\n",
      "----------------------------------\n",
      "Model_3 - Training\n",
      "- Started on 05-08 at 12:49\n",
      "Model_3 - Training Complete\n",
      "- Time: 12.831 min\n",
      "- Loss = 1158.22484\n",
      "- Val Loss = 272.06561\n",
      "----------------------------------\n",
      "Success creating inverse test set\n",
      "----------------------------------\n",
      "Predicting with Model_3\n",
      "Inverse Scaling Operation\n",
      "- Prediction Mean = -0.00178\n",
      "- Prediction Min = -0.00275\n",
      "- Prediction Max = 0.02434\n",
      "Calculating HC Error\n",
      "- HC Error  = 1.64e+08\n",
      "----------------------------------\n",
      "============== MODEL 3 PROCESS END ==============\n",
      " \n",
      "Model_4 Variables:\n",
      "- Loss: MAPE\n",
      "- Activation: LReLU\n",
      "- Output: linear\n",
      "- Optimizer: Adam\n",
      "- Dropout: 20.0%\n",
      "- Scaler: MinMax\n",
      "- Dropped: Displacement\n",
      "----------------------------------\n",
      "Displacement Column Dropped\n",
      "Preparing Data-sets\n",
      "Splitting into inputs and outputs\n",
      "Inputs = 17\n",
      "Data-sets complete\n",
      "----------------------------------\n",
      "Model_4 Created\n",
      "----------------------------------\n",
      "Model_4 - Training\n",
      "- Started on 05-08 at 13:02\n",
      "Model_4 - Training Complete\n",
      "- Time: 12.862 min\n",
      "- Loss = 1236.99300\n",
      "- Val Loss = 127.12011\n",
      "----------------------------------\n",
      "Success creating inverse test set\n",
      "----------------------------------\n",
      "Predicting with Model_4\n",
      "Inverse Scaling Operation\n",
      "- Prediction Mean = -0.00081\n",
      "- Prediction Min = -0.02894\n",
      "- Prediction Max = 0.00010\n",
      "Calculating HC Error\n",
      "- HC Error  = 1.16e+08\n",
      "----------------------------------\n",
      "============== MODEL 4 PROCESS END ==============\n",
      " \n",
      "Model_5 Variables:\n",
      "- Loss: MAPE\n",
      "- Activation: LReLU\n",
      "- Output: linear\n",
      "- Optimizer: Adam\n",
      "- Dropout: 20.0%\n",
      "- Scaler: MinMax\n",
      "- Dropped: Fuel_System\n",
      "----------------------------------\n",
      "Fuel_System Column Dropped\n",
      "Preparing Data-sets\n",
      "Splitting into inputs and outputs\n",
      "Inputs = 17\n",
      "Data-sets complete\n",
      "----------------------------------\n",
      "Model_5 Created\n",
      "----------------------------------\n",
      "Model_5 - Training\n",
      "- Started on 05-08 at 13:15\n",
      "Model_5 - Training Complete\n",
      "- Time: 13.007 min\n",
      "- Loss = 1034.37208\n",
      "- Val Loss = 333.64433\n",
      "----------------------------------\n",
      "Success creating inverse test set\n",
      "----------------------------------\n",
      "Predicting with Model_5\n",
      "Inverse Scaling Operation\n",
      "- Prediction Mean = -0.00320\n",
      "- Prediction Min = -0.00381\n",
      "- Prediction Max = 0.01070\n",
      "Calculating HC Error\n",
      "- HC Error  = 1.63e+08\n",
      "----------------------------------\n",
      "============== MODEL 5 PROCESS END ==============\n",
      " \n",
      "Model_6 Variables:\n",
      "- Loss: MAPE\n",
      "- Activation: LReLU\n",
      "- Output: linear\n",
      "- Optimizer: Adam\n",
      "- Dropout: 20.0%\n",
      "- Scaler: MinMax\n",
      "- Dropped: Gears\n",
      "----------------------------------\n",
      "Gears Column Dropped\n",
      "Preparing Data-sets\n",
      "Splitting into inputs and outputs\n",
      "Inputs = 17\n",
      "Data-sets complete\n",
      "----------------------------------\n",
      "Model_6 Created\n",
      "----------------------------------\n",
      "Model_6 - Training\n",
      "- Started on 05-08 at 13:28\n",
      "Model_6 - Training Complete\n",
      "- Time: 13.089 min\n",
      "- Loss = 1118.76454\n",
      "- Val Loss = 105.02155\n",
      "----------------------------------\n",
      "Success creating inverse test set\n",
      "----------------------------------\n",
      "Predicting with Model_6\n",
      "Inverse Scaling Operation\n",
      "- Prediction Mean = 0.00052\n",
      "- Prediction Min = -0.00400\n",
      "- Prediction Max = 0.00070\n",
      "Calculating HC Error\n",
      "- HC Error  = 6.59e+06\n",
      "----------------------------------\n",
      "============== MODEL 6 PROCESS END ==============\n",
      " \n",
      "Model_7 Variables:\n",
      "- Loss: MAPE\n",
      "- Activation: LReLU\n",
      "- Output: linear\n",
      "- Optimizer: Adam\n",
      "- Dropout: 20.0%\n",
      "- Scaler: MinMax\n",
      "- Dropped: Transmission_Code\n",
      "----------------------------------\n",
      "Transmission_Code Column Dropped\n",
      "Preparing Data-sets\n",
      "Splitting into inputs and outputs\n",
      "Inputs = 17\n",
      "Data-sets complete\n",
      "----------------------------------\n",
      "Model_7 Created\n",
      "----------------------------------\n",
      "Model_7 - Training\n",
      "- Started on 05-08 at 13:41\n",
      "Model_7 - Training Complete\n",
      "- Time: 13.212 min\n",
      "- Loss = 1300.35952\n",
      "- Val Loss = 223.36408\n",
      "----------------------------------\n",
      "Success creating inverse test set\n",
      "----------------------------------\n",
      "Predicting with Model_7\n",
      "Inverse Scaling Operation\n",
      "- Prediction Mean = -0.00183\n",
      "- Prediction Min = -0.00196\n",
      "- Prediction Max = 0.00185\n",
      "Calculating HC Error\n",
      "- HC Error  = 4.33e+07\n",
      "----------------------------------\n",
      "============== MODEL 7 PROCESS END ==============\n",
      " \n",
      "Model_8 Variables:\n",
      "- Loss: MAPE\n",
      "- Activation: LReLU\n",
      "- Output: linear\n",
      "- Optimizer: Adam\n",
      "- Dropout: 20.0%\n",
      "- Scaler: MinMax\n",
      "- Dropped: ETW\n",
      "----------------------------------\n",
      "ETW Column Dropped\n",
      "Preparing Data-sets\n",
      "Splitting into inputs and outputs\n",
      "Inputs = 17\n",
      "Data-sets complete\n",
      "----------------------------------\n",
      "Model_8 Created\n",
      "----------------------------------\n",
      "Model_8 - Training\n",
      "- Started on 05-08 at 13:54\n",
      "Model_8 - Training Complete\n",
      "- Time: 13.224 min\n",
      "- Loss = 832.35982\n",
      "- Val Loss = 125.15075\n",
      "----------------------------------\n",
      "Success creating inverse test set\n",
      "----------------------------------\n",
      "Predicting with Model_8\n",
      "Inverse Scaling Operation\n",
      "- Prediction Mean = 0.00007\n",
      "- Prediction Min = -0.00035\n",
      "- Prediction Max = 0.01607\n",
      "Calculating HC Error\n",
      "- HC Error  = 2.86e+07\n",
      "----------------------------------\n",
      "============== MODEL 8 PROCESS END ==============\n",
      " \n",
      "Model_9 Variables:\n",
      "- Loss: MAPE\n",
      "- Activation: LReLU\n",
      "- Output: linear\n",
      "- Optimizer: Adam\n",
      "- Dropout: 20.0%\n",
      "- Scaler: MinMax\n",
      "- Dropped: HP\n",
      "----------------------------------\n",
      "HP Column Dropped\n",
      "Preparing Data-sets\n",
      "Splitting into inputs and outputs\n",
      "Inputs = 17\n",
      "Data-sets complete\n",
      "----------------------------------\n",
      "Model_9 Created\n",
      "----------------------------------\n",
      "Model_9 - Training\n",
      "- Started on 05-08 at 14:07\n",
      "Model_9 - Training Complete\n",
      "- Time: 13.334 min\n",
      "- Loss = 731.26199\n",
      "- Val Loss = 219.40296\n",
      "----------------------------------\n",
      "Success creating inverse test set\n",
      "----------------------------------\n",
      "Predicting with Model_9\n",
      "Inverse Scaling Operation\n",
      "- Prediction Mean = 0.00333\n",
      "- Prediction Min = -0.00379\n",
      "- Prediction Max = 0.00381\n",
      "Calculating HC Error\n",
      "- HC Error  = 1.41e+08\n",
      "----------------------------------\n",
      "============== MODEL 9 PROCESS END ==============\n",
      " \n",
      "Model_10 Variables:\n",
      "- Loss: MAPE\n",
      "- Activation: LReLU\n",
      "- Output: linear\n",
      "- Optimizer: Adam\n",
      "- Dropout: 20.0%\n",
      "- Scaler: MinMax\n",
      "- Dropped: Drive_System_Code\n",
      "----------------------------------\n",
      "Drive_System_Code Column Dropped\n",
      "Preparing Data-sets\n",
      "Splitting into inputs and outputs\n",
      "Inputs = 17\n",
      "Data-sets complete\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_10 Created\n",
      "----------------------------------\n",
      "Model_10 - Training\n",
      "- Started on 05-08 at 14:21\n",
      "Model_10 - Training Complete\n",
      "- Time: 13.434 min\n",
      "- Loss = 1081.07312\n",
      "- Val Loss = 181.31188\n",
      "----------------------------------\n",
      "Success creating inverse test set\n",
      "----------------------------------\n",
      "Predicting with Model_10\n",
      "Inverse Scaling Operation\n",
      "- Prediction Mean = 0.00048\n",
      "- Prediction Min = -0.00107\n",
      "- Prediction Max = 0.06206\n",
      "Calculating HC Error\n",
      "- HC Error  = 3.91e+08\n",
      "----------------------------------\n",
      "============== MODEL 10 PROCESS END ==============\n",
      " \n",
      "Model_11 Variables:\n",
      "- Loss: MAPE\n",
      "- Activation: LReLU\n",
      "- Output: linear\n",
      "- Optimizer: Adam\n",
      "- Dropout: 20.0%\n",
      "- Scaler: MinMax\n",
      "- Dropped: Fuel_Code\n",
      "----------------------------------\n",
      "Fuel_Code Column Dropped\n",
      "Preparing Data-sets\n",
      "Splitting into inputs and outputs\n",
      "Inputs = 17\n",
      "Data-sets complete\n",
      "----------------------------------\n",
      "Model_11 Created\n",
      "----------------------------------\n",
      "Model_11 - Training\n",
      "- Started on 05-08 at 14:34\n",
      "Model_11 - Training Complete\n",
      "- Time: 13.599 min\n",
      "- Loss = 1255.64982\n",
      "- Val Loss = 111.77668\n",
      "----------------------------------\n",
      "Success creating inverse test set\n",
      "----------------------------------\n",
      "Predicting with Model_11\n",
      "Inverse Scaling Operation\n",
      "- Prediction Mean = 0.00081\n",
      "- Prediction Min = -0.00018\n",
      "- Prediction Max = 0.01939\n",
      "Calculating HC Error\n",
      "- HC Error  = 3.96e+07\n",
      "----------------------------------\n",
      "============== MODEL 11 PROCESS END ==============\n",
      " \n",
      "Model_12 Variables:\n",
      "- Loss: MAPE\n",
      "- Activation: LReLU\n",
      "- Output: linear\n",
      "- Optimizer: Adam\n",
      "- Dropout: 20.0%\n",
      "- Scaler: MinMax\n",
      "- Dropped: V_avg\n",
      "----------------------------------\n",
      "V_avg Column Dropped\n",
      "Preparing Data-sets\n",
      "Splitting into inputs and outputs\n",
      "Inputs = 17\n",
      "Data-sets complete\n",
      "----------------------------------\n",
      "Model_12 Created\n",
      "----------------------------------\n",
      "Model_12 - Training\n",
      "- Started on 05-08 at 14:48\n",
      "Model_12 - Training Complete\n",
      "- Time: 13.696 min\n",
      "- Loss = 1328.89360\n",
      "- Val Loss = 272.69360\n",
      "----------------------------------\n",
      "Success creating inverse test set\n",
      "----------------------------------\n",
      "Predicting with Model_12\n",
      "Inverse Scaling Operation\n",
      "- Prediction Mean = 0.00549\n",
      "- Prediction Min = 0.00319\n",
      "- Prediction Max = 0.10277\n",
      "Calculating HC Error\n",
      "- HC Error  = 1.24e+09\n",
      "----------------------------------\n",
      "============== MODEL 12 PROCESS END ==============\n",
      " \n",
      "Model_13 Variables:\n",
      "- Loss: MAPE\n",
      "- Activation: LReLU\n",
      "- Output: linear\n",
      "- Optimizer: Adam\n",
      "- Dropout: 20.0%\n",
      "- Scaler: MinMax\n",
      "- Dropped: V_max\n",
      "----------------------------------\n",
      "V_max Column Dropped\n",
      "Preparing Data-sets\n",
      "Splitting into inputs and outputs\n",
      "Inputs = 17\n",
      "Data-sets complete\n",
      "----------------------------------\n",
      "Model_13 Created\n",
      "----------------------------------\n",
      "Model_13 - Training\n",
      "- Started on 05-08 at 15:02\n",
      "Model_13 - Training Complete\n",
      "- Time: 13.860 min\n",
      "- Loss = 1078.18399\n",
      "- Val Loss = 144.52187\n",
      "----------------------------------\n",
      "Success creating inverse test set\n",
      "----------------------------------\n",
      "Predicting with Model_13\n",
      "Inverse Scaling Operation\n",
      "- Prediction Mean = -0.00060\n",
      "- Prediction Min = -0.06549\n",
      "- Prediction Max = 0.00079\n",
      "Calculating HC Error\n",
      "- HC Error  = 3.49e+08\n",
      "----------------------------------\n",
      "============== MODEL 13 PROCESS END ==============\n",
      " \n",
      "Model_14 Variables:\n",
      "- Loss: MAPE\n",
      "- Activation: LReLU\n",
      "- Output: linear\n",
      "- Optimizer: Adam\n",
      "- Dropout: 20.0%\n",
      "- Scaler: MinMax\n",
      "- Dropped: V_std\n",
      "----------------------------------\n",
      "V_std Column Dropped\n",
      "Preparing Data-sets\n",
      "Splitting into inputs and outputs\n",
      "Inputs = 17\n",
      "Data-sets complete\n",
      "----------------------------------\n",
      "Model_14 Created\n",
      "----------------------------------\n",
      "Model_14 - Training\n",
      "- Started on 05-08 at 15:15\n",
      "Model_14 - Training Complete\n",
      "- Time: 13.897 min\n",
      "- Loss = 1039.18095\n",
      "- Val Loss = 141.84879\n",
      "----------------------------------\n",
      "Success creating inverse test set\n",
      "----------------------------------\n",
      "Predicting with Model_14\n",
      "Inverse Scaling Operation\n",
      "- Prediction Mean = -0.00084\n",
      "- Prediction Min = -0.02643\n",
      "- Prediction Max = 0.00034\n",
      "Calculating HC Error\n",
      "- HC Error  = 9.84e+07\n",
      "----------------------------------\n",
      "============== MODEL 14 PROCESS END ==============\n",
      " \n",
      "Model_15 Variables:\n",
      "- Loss: MAPE\n",
      "- Activation: LReLU\n",
      "- Output: linear\n",
      "- Optimizer: Adam\n",
      "- Dropout: 20.0%\n",
      "- Scaler: MinMax\n",
      "- Dropped: a_pos\n",
      "----------------------------------\n",
      "a_pos Column Dropped\n",
      "Preparing Data-sets\n",
      "Splitting into inputs and outputs\n",
      "Inputs = 17\n",
      "Data-sets complete\n",
      "----------------------------------\n",
      "Model_15 Created\n",
      "----------------------------------\n",
      "Model_15 - Training\n",
      "- Started on 05-08 at 15:29\n",
      "Model_15 - Training Complete\n",
      "- Time: 14.310 min\n",
      "- Loss = 935.38630\n",
      "- Val Loss = 161.71494\n",
      "----------------------------------\n",
      "Success creating inverse test set\n",
      "----------------------------------\n",
      "Predicting with Model_15\n",
      "Inverse Scaling Operation\n",
      "- Prediction Mean = -0.00036\n",
      "- Prediction Min = -0.00111\n",
      "- Prediction Max = 0.01649\n",
      "Calculating HC Error\n",
      "- HC Error  = 4.43e+07\n",
      "----------------------------------\n",
      "============== MODEL 15 PROCESS END ==============\n",
      " \n",
      "Model_16 Variables:\n",
      "- Loss: MAPE\n",
      "- Activation: LReLU\n",
      "- Output: linear\n",
      "- Optimizer: Adam\n",
      "- Dropout: 20.0%\n",
      "- Scaler: MinMax\n",
      "- Dropped: a_neg\n",
      "----------------------------------\n",
      "a_neg Column Dropped\n",
      "Preparing Data-sets\n",
      "Splitting into inputs and outputs\n",
      "Inputs = 17\n",
      "Data-sets complete\n",
      "----------------------------------\n",
      "Model_16 Created\n",
      "----------------------------------\n",
      "Model_16 - Training\n",
      "- Started on 05-08 at 15:44\n",
      "Model_16 - Training Complete\n",
      "- Time: 14.858 min\n",
      "- Loss = 1080.96425\n",
      "- Val Loss = 313.47082\n",
      "----------------------------------\n",
      "Success creating inverse test set\n",
      "----------------------------------\n",
      "Predicting with Model_16\n",
      "Inverse Scaling Operation\n",
      "- Prediction Mean = 0.00150\n",
      "- Prediction Min = -0.00196\n",
      "- Prediction Max = 0.09603\n",
      "Calculating HC Error\n",
      "- HC Error  = 1.42e+09\n",
      "----------------------------------\n",
      "============== MODEL 16 PROCESS END ==============\n",
      " \n",
      "Model_17 Variables:\n",
      "- Loss: MAPE\n",
      "- Activation: LReLU\n",
      "- Output: linear\n",
      "- Optimizer: Adam\n",
      "- Dropout: 20.0%\n",
      "- Scaler: MinMax\n",
      "- Dropped: Peak_pos\n",
      "----------------------------------\n",
      "Peak_pos Column Dropped\n",
      "Preparing Data-sets\n",
      "Splitting into inputs and outputs\n",
      "Inputs = 17\n",
      "Data-sets complete\n",
      "----------------------------------\n",
      "Model_17 Created\n",
      "----------------------------------\n",
      "Model_17 - Training\n",
      "- Started on 05-08 at 15:59\n",
      "Model_17 - Training Complete\n",
      "- Time: 14.876 min\n",
      "- Loss = 989.92477\n",
      "- Val Loss = 142.57803\n",
      "----------------------------------\n",
      "Success creating inverse test set\n",
      "----------------------------------\n",
      "Predicting with Model_17\n",
      "Inverse Scaling Operation\n",
      "- Prediction Mean = -0.00064\n",
      "- Prediction Min = -0.00171\n",
      "- Prediction Max = -0.00040\n",
      "Calculating HC Error\n",
      "- HC Error  = 5.71e+06\n",
      "----------------------------------\n",
      "============== MODEL 17 PROCESS END ==============\n",
      " \n",
      "Model_18 Variables:\n",
      "- Loss: MAPE\n",
      "- Activation: LReLU\n",
      "- Output: linear\n",
      "- Optimizer: Adam\n",
      "- Dropout: 20.0%\n",
      "- Scaler: MinMax\n",
      "- Dropped: Peak_neg\n",
      "----------------------------------\n",
      "Peak_neg Column Dropped\n",
      "Preparing Data-sets\n",
      "Splitting into inputs and outputs\n",
      "Inputs = 17\n",
      "Data-sets complete\n",
      "----------------------------------\n",
      "Model_18 Created\n",
      "----------------------------------\n",
      "Model_18 - Training\n",
      "- Started on 05-08 at 16:14\n",
      "Model_18 - Training Complete\n",
      "- Time: 15.354 min\n",
      "- Loss = 1350.84896\n",
      "- Val Loss = 140.58691\n",
      "----------------------------------\n",
      "Success creating inverse test set\n",
      "----------------------------------\n",
      "Predicting with Model_18\n",
      "Inverse Scaling Operation\n",
      "- Prediction Mean = 0.00109\n",
      "- Prediction Min = -0.01473\n",
      "- Prediction Max = 0.00167\n",
      "Calculating HC Error\n",
      "- HC Error  = 5.07e+07\n",
      "----------------------------------\n",
      "============== MODEL 18 PROCESS END ==============\n",
      " \n",
      "Model_19 Variables:\n",
      "- Loss: MAPE\n",
      "- Activation: LReLU\n",
      "- Output: linear\n",
      "- Optimizer: Adam\n",
      "- Dropout: 20.0%\n",
      "- Scaler: MinMax\n",
      "- Variance: 1\n",
      "----------------------------------\n",
      "Preparing Data-sets\n",
      "Splitting into inputs and outputs\n",
      "Inputs = 18\n",
      "Data-sets complete\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Model_19 Created\n",
      "----------------------------------\n",
      "Model_19 - Training\n",
      "- Started on 05-08 at 16:29\n",
      "Model_19 - Training Complete\n",
      "- Time: 15.248 min\n",
      "- Loss = 1333.60124\n",
      "- Val Loss = 212.64754\n",
      "----------------------------------\n",
      "Success creating inverse test set\n",
      "----------------------------------\n",
      "Predicting with Model_19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse Scaling Operation\n",
      "- Prediction Mean = 0.00450\n",
      "- Prediction Min = 0.00155\n",
      "- Prediction Max = 0.08381\n",
      "Calculating HC Error\n",
      "- HC Error  = 1.25e+09\n",
      "----------------------------------\n",
      "============== MODEL 19 PROCESS END ==============\n",
      " \n",
      "Model_20 Variables:\n",
      "- Loss: MAPE\n",
      "- Activation: LReLU\n",
      "- Output: linear\n",
      "- Optimizer: Adam\n",
      "- Dropout: 20.0%\n",
      "- Scaler: MinMax\n",
      "- Variance: 0.99\n",
      "----------------------------------\n",
      "Preparing Data-sets\n",
      "Splitting into inputs and outputs\n",
      "Inputs = 18\n",
      "Data-sets complete\n",
      "----------------------------------\n",
      "Create PCA Instance\n",
      "Fit PCA Instance\n",
      "Number of Components = 11\n",
      "Create New Input Training Set\n",
      "Create New Input Dev Set\n",
      "Create New Input Test Set\n",
      "----------------------------------\n",
      "Model_20 Created\n",
      "----------------------------------\n",
      "Model_20 - Training\n",
      "- Started on 05-08 at 16:44\n",
      "Model_20 - Training Complete\n",
      "- Time: 15.745 min\n",
      "- Loss = 1121.40081\n",
      "- Val Loss = 254.55683\n",
      "----------------------------------\n",
      "Success creating inverse test set\n",
      "----------------------------------\n",
      "Predicting with Model_20\n",
      "Inverse Scaling Operation\n",
      "- Prediction Mean = 0.00466\n",
      "- Prediction Min = 0.00116\n",
      "- Prediction Max = 0.11381\n",
      "Calculating HC Error\n",
      "- HC Error  = 2.34e+09\n",
      "----------------------------------\n",
      "============== MODEL 20 PROCESS END ==============\n",
      " \n",
      "Model_21 Variables:\n",
      "- Loss: MAPE\n",
      "- Activation: LReLU\n",
      "- Output: linear\n",
      "- Optimizer: Adam\n",
      "- Dropout: 20.0%\n",
      "- Scaler: MinMax\n",
      "- Variance: 0.9\n",
      "----------------------------------\n",
      "Preparing Data-sets\n",
      "Splitting into inputs and outputs\n",
      "Inputs = 18\n",
      "Data-sets complete\n",
      "----------------------------------\n",
      "Create PCA Instance\n",
      "Fit PCA Instance\n",
      "Number of Components = 7\n",
      "Create New Input Training Set\n",
      "Create New Input Dev Set\n",
      "Create New Input Test Set\n",
      "----------------------------------\n",
      "Model_21 Created\n",
      "----------------------------------\n",
      "Model_21 - Training\n",
      "- Started on 05-08 at 17:00\n",
      "Model_21 - Training Complete\n",
      "- Time: 15.519 min\n",
      "- Loss = 1107.61141\n",
      "- Val Loss = 253.61829\n",
      "----------------------------------\n",
      "Success creating inverse test set\n",
      "----------------------------------\n",
      "Predicting with Model_21\n",
      "Inverse Scaling Operation\n",
      "- Prediction Mean = -0.00223\n",
      "- Prediction Min = -0.00240\n",
      "- Prediction Max = 0.00432\n",
      "Calculating HC Error\n",
      "- HC Error  = 6.67e+07\n",
      "----------------------------------\n",
      "============== MODEL 21 PROCESS END ==============\n",
      " \n",
      "Creating DataFrame\n",
      "Changing DataFrame column names\n",
      "Ranking Models\n"
     ]
    }
   ],
   "source": [
    "HC_ranking, models, histories = process_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Activation</th>\n",
       "      <th>Output</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Variable/Variance</th>\n",
       "      <th>MSPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Model_17</td>\n",
       "      <td>MinMax</td>\n",
       "      <td>LReLU</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Peak_pos</td>\n",
       "      <td>5.709966e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Model_6</td>\n",
       "      <td>MinMax</td>\n",
       "      <td>LReLU</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Gears</td>\n",
       "      <td>6.586152e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Model_8</td>\n",
       "      <td>MinMax</td>\n",
       "      <td>LReLU</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.2</td>\n",
       "      <td>ETW</td>\n",
       "      <td>2.859548e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Model_11</td>\n",
       "      <td>MinMax</td>\n",
       "      <td>LReLU</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Fuel_Code</td>\n",
       "      <td>3.956765e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Model_7</td>\n",
       "      <td>MinMax</td>\n",
       "      <td>LReLU</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Transmission_Code</td>\n",
       "      <td>4.334964e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Model_15</td>\n",
       "      <td>MinMax</td>\n",
       "      <td>LReLU</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.2</td>\n",
       "      <td>a_pos</td>\n",
       "      <td>4.425015e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Model_18</td>\n",
       "      <td>MinMax</td>\n",
       "      <td>LReLU</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Peak_neg</td>\n",
       "      <td>5.069752e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model_2</td>\n",
       "      <td>MinMax</td>\n",
       "      <td>LReLU</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Vehicle_Code</td>\n",
       "      <td>6.249397e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Model_21</td>\n",
       "      <td>MinMax</td>\n",
       "      <td>LReLU</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>6.674133e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Model_14</td>\n",
       "      <td>MinMax</td>\n",
       "      <td>LReLU</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.2</td>\n",
       "      <td>V_std</td>\n",
       "      <td>9.840734e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model_1</td>\n",
       "      <td>MinMax</td>\n",
       "      <td>LReLU</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Year</td>\n",
       "      <td>1.033827e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model_4</td>\n",
       "      <td>MinMax</td>\n",
       "      <td>LReLU</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Displacement</td>\n",
       "      <td>1.158960e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Model_9</td>\n",
       "      <td>MinMax</td>\n",
       "      <td>LReLU</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.2</td>\n",
       "      <td>HP</td>\n",
       "      <td>1.411387e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model_5</td>\n",
       "      <td>MinMax</td>\n",
       "      <td>LReLU</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Fuel_System</td>\n",
       "      <td>1.630067e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model_3</td>\n",
       "      <td>MinMax</td>\n",
       "      <td>LReLU</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Manufacturer_Code</td>\n",
       "      <td>1.644564e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Model_13</td>\n",
       "      <td>MinMax</td>\n",
       "      <td>LReLU</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.2</td>\n",
       "      <td>V_max</td>\n",
       "      <td>3.488139e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Model_10</td>\n",
       "      <td>MinMax</td>\n",
       "      <td>LReLU</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Drive_System_Code</td>\n",
       "      <td>3.906998e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Model_12</td>\n",
       "      <td>MinMax</td>\n",
       "      <td>LReLU</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.2</td>\n",
       "      <td>V_avg</td>\n",
       "      <td>1.242420e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Model_19</td>\n",
       "      <td>MinMax</td>\n",
       "      <td>LReLU</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.254131e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Model_16</td>\n",
       "      <td>MinMax</td>\n",
       "      <td>LReLU</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.2</td>\n",
       "      <td>a_neg</td>\n",
       "      <td>1.421337e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Model_20</td>\n",
       "      <td>MinMax</td>\n",
       "      <td>LReLU</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2.342672e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  Scaler Activation  Output  Dropout  Variable/Variance  \\\n",
       "16  Model_17  MinMax      LReLU  linear      0.2           Peak_pos   \n",
       "5    Model_6  MinMax      LReLU  linear      0.2              Gears   \n",
       "7    Model_8  MinMax      LReLU  linear      0.2                ETW   \n",
       "10  Model_11  MinMax      LReLU  linear      0.2          Fuel_Code   \n",
       "6    Model_7  MinMax      LReLU  linear      0.2  Transmission_Code   \n",
       "14  Model_15  MinMax      LReLU  linear      0.2              a_pos   \n",
       "17  Model_18  MinMax      LReLU  linear      0.2           Peak_neg   \n",
       "1    Model_2  MinMax      LReLU  linear      0.2       Vehicle_Code   \n",
       "20  Model_21  MinMax      LReLU  linear      0.2                0.9   \n",
       "13  Model_14  MinMax      LReLU  linear      0.2              V_std   \n",
       "0    Model_1  MinMax      LReLU  linear      0.2               Year   \n",
       "3    Model_4  MinMax      LReLU  linear      0.2       Displacement   \n",
       "8    Model_9  MinMax      LReLU  linear      0.2                 HP   \n",
       "4    Model_5  MinMax      LReLU  linear      0.2        Fuel_System   \n",
       "2    Model_3  MinMax      LReLU  linear      0.2  Manufacturer_Code   \n",
       "12  Model_13  MinMax      LReLU  linear      0.2              V_max   \n",
       "9   Model_10  MinMax      LReLU  linear      0.2  Drive_System_Code   \n",
       "11  Model_12  MinMax      LReLU  linear      0.2              V_avg   \n",
       "18  Model_19  MinMax      LReLU  linear      0.2                  1   \n",
       "15  Model_16  MinMax      LReLU  linear      0.2              a_neg   \n",
       "19  Model_20  MinMax      LReLU  linear      0.2               0.99   \n",
       "\n",
       "            MSPE  \n",
       "16  5.709966e+06  \n",
       "5   6.586152e+06  \n",
       "7   2.859548e+07  \n",
       "10  3.956765e+07  \n",
       "6   4.334964e+07  \n",
       "14  4.425015e+07  \n",
       "17  5.069752e+07  \n",
       "1   6.249397e+07  \n",
       "20  6.674133e+07  \n",
       "13  9.840734e+07  \n",
       "0   1.033827e+08  \n",
       "3   1.158960e+08  \n",
       "8   1.411387e+08  \n",
       "4   1.630067e+08  \n",
       "2   1.644564e+08  \n",
       "12  3.488139e+08  \n",
       "9   3.906998e+08  \n",
       "11  1.242420e+09  \n",
       "18  1.254131e+09  \n",
       "15  1.421337e+09  \n",
       "19  2.342672e+09  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HC_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_vector=np.linspace(1,epochs,epochs)\n",
    "\n",
    "for i in range(len(models)):\n",
    "    model = models[i]\n",
    "    history = histories[i]\n",
    "    activation = HC_ranking['Activation'][i]\n",
    "    output = HC_ranking['Output'][i]\n",
    "    variable = HC_ranking['Variable/Variance'][i]\n",
    "    \n",
    "    model.save(os.path.join(output_path,'{}_{}_{}_{}.h5'.format(model.name, activation, output, variable)))\n",
    "    \n",
    "    hist_data =[epoch_vector,history.history['loss'],history.history['val_loss']]\n",
    "    hist_data =pd.DataFrame(hist_data).transpose()\n",
    "    hist_data.columns=['Epochs','loss','val_loss']\n",
    "    \n",
    "    hist_data.to_csv(os.path.join(output_path,'Training_History_{}.csv'.format(model.name)),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models and the training histories will be moved to foldr **Gen 8**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
